{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Using GingerIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import LancasterStemmer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "import plotly.tools as tls   \n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gingerit.gingerit import GingerIt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/Users/Aniket/MyStuff/Study/GreyAtom/Hackathon#3/Hack3_gen_functions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Hackathon3GeneralFunctions as genf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_iphone4(text):\n",
    "    iphone4_pat = r\"iphone[ ]+4\"\n",
    "    return re.sub(iphone4_pat, 'iPhone4', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ipads(text):\n",
    "    #1\n",
    "    ipads_pat = r\"ipads\"\n",
    "    return re.sub(ipads_pat, 'ipad', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ipad2(text):\n",
    "    #2\n",
    "    ipad2_pat = r\"ipad[ ]+2[s]?\"\n",
    "    return re.sub(ipad2_pat, 'ipad2', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_brand(text):\n",
    "    #EDA\n",
    "    iphone_pat = r\"iphone\"\n",
    "    ipad_pat = r\"ipad\"\n",
    "    apple_pat = r\"apple\"\n",
    "    temp = text\n",
    "    temp = re.sub(iphone_pat, 'iPhone', temp, flags=re.I)\n",
    "    temp = re.sub(ipad_pat, 'iPad', temp, flags=re.I)\n",
    "    temp = re.sub(apple_pat, 'Apple', temp, flags=re.I)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_amp(text):\n",
    "    pat_amp = r\"&amp;\"\n",
    "    return re.sub(pat_amp, '&', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_amp(text):\n",
    "    pat_amp_single = r\" & \"\n",
    "    return re.sub(pat_amp_single, '', text, flags=re.I)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_amp_op(text):\n",
    "    pat_amp_single = r\" & |& | &\"\n",
    "    return re.sub(pat_amp_single, '', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(nlp, text):\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    lnlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    return lemma(lnlp, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html_syn(text):    \n",
    "#     html_syn_pat = r\"&lt;[a-z]+&gt;\"\n",
    "    html_syntax_pat = r\"&lt;[/a-z]+&gt;\"\n",
    "    return re.sub(html_syntax_pat, ' ', text, flags=re.I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_text_emoji(text):\n",
    "    love_pat = r\"&lt;3+\"\n",
    "    happy_pat = r\":[-]?[\\)]+\"\n",
    "    sad_pat = r\":[-]?[\\(]+\"\n",
    "    playful_pat = r\":[-]?[p]+\"\n",
    "    wink_pat = r\";[-]?[\\)]+\"\n",
    "    straightface_pat = r\":[-]?[\\|]+\"\n",
    "    \n",
    "    #replace text emojis\n",
    "    temp = text\n",
    "    temp =  re.sub(love_pat, ' love ', temp)\n",
    "    temp =  re.sub(happy_pat, ' smiley ', temp)\n",
    "    temp =  re.sub(sad_pat, ' sad ', temp)\n",
    "    temp =  re.sub(playful_pat, ' playful ', temp, flags=re.I)\n",
    "    temp =  re.sub(wink_pat, ' wink ', temp)\n",
    "    temp =  re.sub(straightface_pat, ' straightface ', temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_before_cleaning(text):\n",
    "    temp = text\n",
    "    temp = map_iphone4(temp)\n",
    "    temp = map_ipads(temp)\n",
    "    temp = map_ipad2(temp)\n",
    "    temp = remove_html_syn(temp)\n",
    "    temp = replace_amp(temp)\n",
    "    temp = remove_amp(temp)\n",
    "    temp = replace_text_emoji(temp)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = GingerIt()\n",
    "# line= \"I loooveee Apple's new iPad ipad 2 with AT&T/GSM&D deal #ipad2\"\n",
    "# tweet=parser.parse(line)\n",
    "# tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on -PRON- foot for good'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize spacy 'en' model, keeping only tagger component needed for lemmatization\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "sentence = \"The striped bats are hanging on their feet for best\"\n",
    "\n",
    "# Parse the sentence using the loaded 'en' model object `nlp`\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Extract the lemma for each token and join\n",
    "\" \".join([token.lemma_ for token in doc])\n",
    "#> 'the strip bat be hang on -PRON- foot for good'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stripe bat be hang on -PRON- foot for good # apple Apple'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_text(\"The striped bats are hanging on their feet for best #apple Apple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' This is a title '"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_html_syn(\"&lt;title&gt;This is a title&lt;/title&gt;\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' love  ipad2 iPhone4s &lt;   #ipad2'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refine_before_cleaning(\"&lt;3 ipad 2 iphone 4s &lt; &lt;title&gt; #ipad2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv', encoding='utf-8')\n",
    "data_gin = train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[0:10,'tweet'].map(refine_before_cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gin['tweet'] = data_gin['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    #sxswnui #sxsw #apple defining language of tou...\n",
       "1    Learning ab Google doodles! All doodles should...\n",
       "2    one of the most in-your-face ex. of stealing t...\n",
       "3    This iPhone #SXSW app would b pretty awesome i...\n",
       "4    Line outside the Apple store in Austin waiting...\n",
       "Name: tweet_cleaned, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gin['tweet_cleaned'] = data_gin['tweet'].map(refine_before_cleaning)\n",
    "data_gin['tweet_cleaned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gin['tweet_cleaned'] = data_gin['tweet_cleaned'].map(lambda x: genf.clean_text(x,lower=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     sxswnui  sxsw  apple defining language of tou...\n",
       "1    Learning ab Google doodles  All doodles should...\n",
       "2    one of the most in your face ex  of stealing t...\n",
       "3    This iPhone  SXSW app would b pretty awesome i...\n",
       "4    Line outside the Apple store in Austin waiting...\n",
       "Name: tweet_cleaned, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_gin['tweet_cleaned'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gin['tweet_cleaned'] = data_gin['tweet_cleaned'].map(remove_amp_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = GingerIt()\n",
    "# line= \"I loooveee Apple's new iPad ipad 2 with AT&T/GSM&D deal #ipad2\"\n",
    "# tweet=parser.parse(line)\n",
    "\n",
    "data_gin['tweet_cleaned_gin'] = data_gin['tweet_cleaned'].map(lambda x: parser.parse(x)['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
